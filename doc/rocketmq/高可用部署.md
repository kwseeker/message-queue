# 高可用部署

## 部署注意

RocketMQ部署时都需要考虑哪些配置。

### 服务节点数量

线上高可用集群NameServer至少是两个节点，Broker至少两主两从，线上用dledger模式（支持auto fail-over）。

多Master为了确保其中一个Master宕机后，消息可以写入到另一个Master；而设置Slave是为了确保Master故障后消费者依旧可以通过Slave消费消息。

Master负责响应客户端的请求，并存储消息。Slave则只负责对master的消息进行同步保存，并响应部分客户端的读请求。

dleger模式支持当Master节点挂了后，通过Raft协议从Slave中自动选出一个节点升级成为master。

线上使用dleger模式是因为其他几种模式中即使可用性最高的多主多从

> NameServer 是一个非常简单的 Topic 路由注册中心；主要包括两个功能：
>
> **Broker 管理**，NameServer 接受 Broker 集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查 Broker 是否还存活；
>
> **路由信息管理**，每个 NameServer 将保存关于 Broker 集群的整个路由信息和用于客户端查询的队列信息。然后 Producer 和 Conumser 通过 NameServer 就可以知道整个 Broker 集群的路由信息，从而进行消息的投递和消费。
>
> NameServer 通常也是集群的方式部署，**各实例间相互不进行信息通讯**。Broker 是向每一台 NameServer 注册自己的路由信息，所以每一个 NameServer 实例上面都保存一份完整的路由信息。当某个 NameServer 因某种原因下线了，Broker 仍然可以向其它 NameServer 同步其路由信息，Producer,Consumer 仍然可以动态感知 Broker 的路由的信息。
>
> RocketMQ 自己开发服务注册中心 NameServer 是因为只需要一个轻量级的元数据服务器就足够了，只需要保持最终一致，而不需要 Zookeeper 这样的强一致性解决方案，不需要再依赖另一个中间件，从而减少整体维护成本。根据 CAP 理论，RocketMQ 在名称服务这个模块的设计上选择了 **AP**，而不是 **CP**。

### 主从模式刷盘方式的选择

RocketMQ支持两种刷盘机制，同步刷盘和异步刷盘。

应用对消息的可靠性要求较高，可以选择同步刷盘方式；如果应用对性能要求较高，可以选择异步刷盘方式。

> Linux 应用程序写文件时，内容并不会直接写入到磁盘当中，而是会先写入到操作系统的**PageCache**缓存中。PageCache缓存以4K大小为单位，缓存写入的内容。对于有数据修改的PageCache，会标记为Dirty(脏页)状态。当Dirty Page的比例达到一定的阈值时，会触发一次刷盘操作真正写入磁盘，或者在正常关机等特定时刻将PageCache数据写入磁盘。
>
> 同步刷盘：（刷盘完成后才返回写成功）
>
> 消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘（fsync函数）， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。
>
> 异步刷盘：（写入PageCache后即返回写成功）
>
> 消息写入PageCache后即返回写成功状态，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。相对于同步刷盘可能丢失数据、但是性能更高。但是官方文档说

配置参数：flushDiskType，选择 SYNC_FLUSH、ASYNC_FLUSH 中的 一个。



## dledger高可用集群搭建

参考：[主备自动切换模式部署](https://rocketmq.apache.org/zh/docs/deploymentOperations/03autofailover)

这里搭建的本地伪集群。

> 注意配置文件中配置行后面不要写注释，经测试这样会启动失败。

**NameServer配置与启动**：

5.0 的 Controller 模式本地部署失败，暂不知道什么原因（TODO 有空看源码查下问题）；

```properties
# n0
# enableControllerInNamesrv = true
# listenPort = 9876
# controllerDLegerGroup = KwseekerControllerCluster
# controllerDLegerPeers = n0-127.0.0.1:9876;n1-127.0.0.1:9877;n2-127.0.0.1:9878
# controllerDLegerSelfId = n0
# controllerStorePath = /tmp/rmqstore/kdc/namesrv00
listenPort = 9877

# n1
# enableControllerInNamesrv = true
# listenPort = 9877
# controllerDLegerGroup = KwseekerControllerCluster
# controllerDLegerPeers = n0-127.0.0.1:9876;n1-127.0.0.1:9877;n2-127.0.0.1:9878
# controllerDLegerSelfId = n1
# controllerStorePath = /tmp/rmqstore/kdc/namesrv01
listenPort = 9878

# n2
# enableControllerInNamesrv = true
# listenPort = 9878
# controllerDLegerGroup = KwseekerControllerCluster
# controllerDLegerPeers = n0-127.0.0.1:9876;n1-127.0.0.1:9877;n2-127.0.0.1:9878
# controllerDLegerSelfId = n2
# controllerStorePath = /tmp/rmqstore/kdc/namesrv02
# # enableElectUncleanMaster = false
# # notifyBrokerRoleChanged = true
listenPort = 9879
```

本地测试，减少内存分配：

```shell
JAVA_OPT="${JAVA_OPT} -server -Xms256m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m"
```

**Broker配置与启动**：

至少3个节点。复制 conf/dledger 改名 kwseeker-dledger-cluster，修改配置。

[broker配置](https://rocketmq.apache.org/zh/docs/bestPractice/01bestpractice#broker-%E9%85%8D%E7%BD%AE)

n0:

```properties
brokerClusterName = KwseekerDledgerCluster
# 同一个集群中的 brokerName 必须相同，不然会选举Master失败
brokerName=KdcNode
listenPort=30911
namesrvAddr=127.0.0.1:9877;127.0.0.1:9878;127.0.0.1:9879
# namesrvAddr=127.0.0.1:9876
storePathRootDir=/tmp/rmqstore/kdc/node00
storePathCommitLog=/tmp/rmqstore/kdc/node00/commitlog
enableDLegerCommitLog=true
dLegerGroup=KdcNode
dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913
## must be unique
dLegerSelfId=n0
sendMessageThreadPoolNums=8
brokerIP1=127.0.0.1
autoCreateTopicEnable=true
```

n1:

```properties
brokerClusterName = KwseekerDledgerCluster
brokerName=KdcNode
listenPort=30921
namesrvAddr=127.0.0.1:9877;127.0.0.1:9878;127.0.0.1:9879
# namesrvAddr=127.0.0.1:9876
storePathRootDir=/tmp/rmqstore/kdc/node01
storePathCommitLog=/tmp/rmqstore/kdc/node01/commitlog
enableDLegerCommitLog=true
dLegerGroup=KdcNode
dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913
## must be unique
dLegerSelfId=n1
sendMessageThreadPoolNums=8
brokerIP1=127.0.0.1
autoCreateTopicEnable=true
```

n2:

```properties
brokerClusterName = KwseekerDledgerCluster
brokerName=KdcNode
listenPort=30931
namesrvAddr=127.0.0.1:9877;127.0.0.1:9878;127.0.0.1:9879
# namesrvAddr=127.0.0.1:9876
storePathRootDir=/tmp/rmqstore/kdc/node02
storePathCommitLog=/tmp/rmqstore/kdc/node02/commitlog
enableDLegerCommitLog=true
dLegerGroup=KdcNode
dLegerPeers=n0-127.0.0.1:40911;n1-127.0.0.1:40912;n2-127.0.0.1:40913
## must be unique
dLegerSelfId=n2
sendMessageThreadPoolNums=8
brokerIP1=127.0.0.1
autoCreateTopicEnable=true
```

broker jvm 参数修改（runbroker.sh）：

```shell
# 默认8G,本地测试，没那么多内存
JAVA_OPT="${JAVA_OPT} -server -Xms256M -Xmx2g"
```

创建日志目录：`mkdir /tmp/rmqstore/kdc/log`

启动：

```shell
cd /home/lee/bin/rocketmq/rocketmq-all-5.1.0-bin-release/bin
mkdir -p /tmp/rmqstore/kdc/log/

echo "start namesrv cluster"
# nohup ./mqnamesrv > /tmp/rmqstore/kdc/log/namesrv.log 2>&1 &
nohup ./mqnamesrv -c ../conf/kwseeker-dledger-cluster/namesrv-n0.conf > /tmp/rmqstore/kdc/log/namesrv00.log 2>&1 &
nohup ./mqnamesrv -c ../conf/kwseeker-dledger-cluster/namesrv-n1.conf > /tmp/rmqstore/kdc/log/namesrv01.log 2>&1 &
nohup ./mqnamesrv -c ../conf/kwseeker-dledger-cluster/namesrv-n2.conf > /tmp/rmqstore/kdc/log/namesrv02.log 2>&1 &

echo "start broker cluster"
nohup ./mqbroker -c ../conf/kwseeker-dledger-cluster/broker-n0.conf > /tmp/rmqstore/kdc/log/broker00.log 2>&1 &
nohup ./mqbroker -c ../conf/kwseeker-dledger-cluster/broker-n1.conf > /tmp/rmqstore/kdc/log/broker01.log 2>&1 &
nohup ./mqbroker -c ../conf/kwseeker-dledger-cluster/broker-n2.conf > /tmp/rmqstore/kdc/log/broker02.log 2>&1 &
```

**命令行查看dleger集群的状态**：

```
sh bin/mqadmin clusterList -n 127.0.0.1:9877
```

**dashboard启动**：

使用docker启动，由于前面的broker都是本地启动的，这里要配置 `--network host `共享本地网络。

```
docker run -d \
	--name rocketmq-dashboard \
    --network host \
    -e "JAVA_OPTS=-Drocketmq.namesrv.addr=127.0.0.1:9877" \
    -p 8080:8080 \
    -t apacherocketmq/rocketmq-dashboard:latest
```



## 系统参数调优

